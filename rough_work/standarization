ğŸˆ Imagine a World Without Standardization

Long agoâ€¦
People had different kinds of numbers:

height of people

weight

temperature

money

speed

marks in exams

pixel values in images

All completely different scales.

One scientist said:

â€œHow can I compare a person's height (170 cm) with exam marks (80/100) or money (â‚¹1000)?â€
â€œThese numbers are too different!â€

To compare things fairly, they needed a way to make all numbers behave like the same type.

ğŸ¯ Real Problem Example (Kid Version)

Imagine you and your brother Aafi are in a competition:

You run fast ğŸƒâ€â™‚ï¸

Aafi solves puzzles quickly ğŸ§©

How can we compare â€œrunning speedâ€ and â€œpuzzle-solving speedâ€?
These are completely different numbers!

Scientists needed a universal scale.

ğŸˆ Then Came the Magic Idea: Center Everything!

One super smart mathematician said:

â€œLetâ€™s make everything start from zero.
Remove the average from every number.â€

Example:
Your exam marks: [70, 80, 90]
Mean = 80

Subtract mean:

[-10, 0, +10]


Now the numbers tell a story:

-10 = below average

0 = average

+10 = above average

This is the first half of standardization.

This part is simple, right?
This idea existed hundreds of years ago.

ğŸ¢ But Shapes Were Differentâ€¦ Problem!

Even after centering to zero, different datasets still had different spread.

Example:

Dataset A: [1,2,3,4,5] â†’ small spread
Dataset B: [10,50,100,200,500] â†’ huge spread

Even after subtracting the mean, spreads were different.

To compare fairly, we need spreads to be same.

ğŸ’¡ Then someone had a genius idea: â€œMeasure the spread!â€

But how do you measure spread of numbers?
Scientists tested MANY methods:

âŒ Method 1: Just look at max-min

Problem: fails if outliers exist.

âŒ Method 2: Average distance from mean

Problem: positive and negative distances cancel each other.

â­ Method 3: Square the distances

This solved everything!

Squaring removes negatives

Bigger differences get more importance

Mathematics becomes clean & smooth

Works for all datasets on Earth

This created a new idea:

Variance = average of squared distances from mean

And its square root:

Standard deviation = natural measure of spread

Boom!
This is how the formula was born.

ğŸ¡ So Why Standardization Looks â€œComplexâ€?

Because it combines two ideas:

âœ” Idea 1 (Old): Shift everything to zero

x âˆ’ mean

âœ” Idea 2 (New): Make spreads equal

/ std

Combine them:

z = (x âˆ’ mean) / std


Thatâ€™s it.

Not complex â€” just two simple ideas combined.

ğŸŒ How Did This Appear in the Real World?

Standardization was invented because:

1ï¸âƒ£ Scientists compared different measurements

Heights, weights, intelligence scores, rainfall, temperaturesâ€¦
Everything needed one universal scale.

2ï¸âƒ£ Banks needed it

To compare incomes of people, loan risk, salaries.

3ï¸âƒ£ Psychologists needed it
To compare IQ scores across countries.

4ï¸âƒ£ Machine Learning needs it

Algorithms canâ€™t understand â€œbig numbersâ€ like 1000 or small numbers like 0.01.
Standardization makes everything look the same.

â¤ï¸ Kid-Level Final Summary

Imagine you have toys of all sizes.
You want them to fit in one box.

So you:

1ï¸âƒ£ Subtract the mean
â†’ move toys so they start from the same point.

2ï¸âƒ£ Divide by standard deviation
â†’ shrink or stretch toys so they are same size.

Now everything fits in one box.
That box is called standardized data.



â­ Why Computers Prefer Standardized Values?
âœ” Matrix multiplication becomes faster

Numbers between -1 and 1 are easier to compute.

âœ” Fewer memory problems

Large numbers cause computational instability.

âœ” Better numerical precision

Floating-point calculations become more accurate.




âœ… Q1. Standardize the array [2, 4, 6, 8]
mean = (2 + 4 + 6 + 8) / 4 = 20/4 = 5

Step 2: Standard Deviation

Values from mean:

2 â†’ -3
4 â†’ -1
6 â†’ +1
8 â†’ +3


Square them:

9, 1, 1, 9


Mean of squares:

(9 + 1 + 1 + 9) / 4 = 20/4 = 5


Std = âˆš5
â‰ˆ 2.236
Formula:

z = (x - mean) / std


For each value:

x	(x-5)/2.236	result
2	-3/2.236	-1.34
4	-1/2.236	-0.45
6	1/2.236	+0.45
8	3/2.236	+1.34
âœ” Final Answer:
[-1.34, -0.45, 0.45, 1.34]

âœ… Q3. Why do we standardize before training a neural network?
âœ” Answer:

Because neural networks learn using gradient descent, and standardization makes the learning faster, stable, and prevents one feature from dominating others.

âœ… Q4. Which will dominate KNN â€” Age or Salary?
Feature	Range
Age	20â€“50
Salary	20,000â€“80,000
âœ” Salary will dominate.

Because its values are much larger, so distance calculations become unfair.

KNN will think salary is more important (even if itâ€™s not).

âœ… Q5. After standardization, the mean and std become?

Always:

Metric	Value
Mean	0
Standard deviation	1

Thatâ€™s the purpose of standardization.


lets visualize the standardization:
let be have numbers:2,4,6,8,10

2                        -4                         16
4                        -2                          4
6     ------mean(6)-------0------square(x-mean)------0--------mean(7.2)-------sqrt(7.2)=std
8                         2                          4
10                        4                         16

x-mean:
{
2-6=-4
4-6=-2
6-6=0
8-6=2
10-6=4
}

z=x-mean/std

